{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of sung_lec02_multilinear_regression(4)_주식가격예측.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sturu1/git-first/blob/master/Copy_of_sung_lec02_multilinear_regression(4)_%EC%A3%BC%EC%8B%9D%EA%B0%80%EA%B2%A9%EC%98%88%EC%B8%A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QY04i5j0dNU",
        "colab_type": "text"
      },
      "source": [
        "# 주식 가격 예측\n",
        "\n",
        "> 이번에는 보다 많은 데이터를 기반으로 multiple linear regression을 수행해 보겠습니다. 본 예제에서는 아래 주소에 있는 csv파일을 불러들여서 multiple linear regression을 수행해 보겠습니다. \n",
        "\n",
        "> 자료출처: https://github.com/hunkim/DeepLearningZeroToAll/tree/master/keras \n",
        "\n",
        "> 오늘 사용할 모델은 다음과 같이 수식으로 표현할 수 있습니다. \n",
        "```\n",
        "y=w1*x1 + w2*x2 + w3*x3 + w3*x3 + b\n",
        "```\n",
        "\n",
        "> 오늘 예제를 통해 여러분은 간단한(정확도가 높지않은) 주가 예측 인공지능을 만들어 볼 수 있습니다. \n",
        "또한, **데이터 정규화**에 대한 내용도 여러분이 꼭 학습하셔야 합니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2la6xRaMa0m",
        "colab_type": "text"
      },
      "source": [
        "> 먼저 데이터를 불러서 여러분의 작업환경에 저장하겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd4L6al2sqqd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "19c7a10f-d0e9-4a6e-fe37-ae64ce71874a"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/hunkim/DeepLearningZeroToAll/master/keras/data-02-stock_daily.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-11 08:16:55--  https://raw.githubusercontent.com/hunkim/DeepLearningZeroToAll/master/keras/data-02-stock_daily.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37037 (36K) [text/plain]\n",
            "Saving to: ‘data-02-stock_daily.csv’\n",
            "\n",
            "\rdata-02-stock_daily   0%[                    ]       0  --.-KB/s               \rdata-02-stock_daily 100%[===================>]  36.17K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-06-11 08:16:55 (2.42 MB/s) - ‘data-02-stock_daily.csv’ saved [37037/37037]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "788DSxrkPytx",
        "colab_type": "text"
      },
      "source": [
        "> 여러분의 디렉토리에 저장된 data-02-stock_daily.csv 파일을 읽어서 xy라는 변수에 저장합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-O60cP0tGga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03fb15ce-dca6-4326-f21e-44461937e3c1"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data-02-stock_daily.csv  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TncKIx9sdLfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "xy = np.loadtxt(\"data-02-stock_daily.csv\", delimiter=',', dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuAXc20-djRw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc375db6-06cd-409e-d131-68d5d6acd7a6"
      },
      "source": [
        "xy.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(732, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMSFizp5Mwye",
        "colab_type": "text"
      },
      "source": [
        "> 자료를 보면 각 일자별로 주식 가격에 대한 다음과 같은 5가지 정보가 기록되어 있습니다. \n",
        "* 장 시작가(시가), 최고가(고가), 최저가(저가), 거래량, 종가\n",
        "* (Open,High,Low,Volume,Close)\n",
        "\n",
        "> 총 732일에 대한 자료입니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD88VWxuz8jU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al9LpWeA0Iyr",
        "colab_type": "text"
      },
      "source": [
        "필요한 모듈을 불러옵니다. \n",
        "이번에는 sklearn 모듈을 추가로 활용하는데, **데이터 정규화**를 위해서 필요합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5dbk9_ts6Q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8Ouhrw_eDjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKe4urFmPAA-",
        "colab_type": "text"
      },
      "source": [
        "> 다음으로 학습을 위한 데이터를 입력 및 출력 변수로 나누어 저장합니다. 아래서 보는바와 같이 입력데이터는 732개의 개체(sample)가 있으며, 각 개체별로 5개의 변수(속성)를 갖고 있습니다. 즉, 732일의 일자동안, 각 일자별로 4개의 속성으로 입력데이터를 구성합니다. 또한 출력데이터는 732개의 개체와 각 개체별 1개의 속성(종가)으로 구성되어 있습니다.\n",
        "\n",
        "> 이 문제는 **전날의 4가지 입력정보**, 즉 시가, 고가, 저가, 거래량을 바탕으로 **다음날의 종가를 예측**하는 문제입니다. 이를 위해서 몇가지 작업이 필요합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjO9-DD14G-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_data = xy[:, :-1]\n",
        "y_data = xy[:, [-1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0FrT5sVefKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "3742ffc1-0f71-4ebc-8a09-603b92d3d7e5"
      },
      "source": [
        "x_data.shape, y-data.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-66ef9ba7fcd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8E_djGGNZse",
        "colab_type": "text"
      },
      "source": [
        "> 딥러닝을 학습할때 중요한 한가지가 있습니다. 바로 **데이터의 정규화** (data normalization) 입니다. \n",
        "\n",
        "> 정규화에 대한 구체적인 얘기는 뒤에 다시하도록 하고, 여기서는 간단히 입력데이터 값을 [0,1] 사이의 값으로 변환하는 것을 의미한다는 정도만 설명하겠습니다. \n",
        "\n",
        "> 이렇게 데이터를 사전에 특정 범위 내로 변환하는 이유는, 정규화가 딥러닝의 성능을 높일 수 있기 때문입니다. \n",
        "\n",
        "> 앞선 예제들에서는 정규화 과정이 별도로 없었지만, 사실 모든 딥러닝 문제에서는 정규화 과정을 거의 항상 거친다고 봐도 무방합니다. \n",
        "\n",
        "> 본 절에서는 정규화를 수행하기 위해 머신러닝 모듈인 scikit_learn에서 재공하는 MinMaxScaler 함수(클래스)를 사용하겠습니다. \n",
        "\n",
        "> MinMaxScaler 함수는 주어진 데이터를 정해진 범위(feature_range)내의 값으로 변환해 주는 역할을 합니다. \n",
        "\n",
        "> 먼저, MinMaxScaler 클래스를 이용하여 0~1로 정규화를 해주는 scaler라는 instance를 생성합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qdtT8SStTk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler=MinMaxScaler(feature_range=(0,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsBPAqigO9Ne",
        "colab_type": "text"
      },
      "source": [
        "> 생성된 scaler instance를 사용하여 입력데이터의 값의 범위를 0과 1사이로 변환합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEInXpdGtph6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_data = scaler.fit_transform(x_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5zdnEdifAJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "093ecf91-be40-434d-8454-aa4c9c1b8146"
      },
      "source": [
        "x_data"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.7333574e-01, 9.7543156e-01, 1.0000000e+00, 1.1112306e-01],\n",
              "       [9.5690036e-01, 9.5988119e-01, 9.8035455e-01, 1.4250247e-01],\n",
              "       [9.4789577e-01, 9.4927347e-01, 9.7250485e-01, 1.1417048e-01],\n",
              "       ...,\n",
              "       [2.1051645e-01, 2.0528936e-01, 2.0355880e-01, 2.5992648e-04],\n",
              "       [1.9393516e-01, 2.0364201e-01, 2.0866466e-01, 2.9846733e-03],\n",
              "       [2.1375108e-01, 2.0817983e-01, 1.9179189e-01, 4.6607509e-04]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YGtNJxmRKIO",
        "colab_type": "text"
      },
      "source": [
        "> 입력데이터의 값이 0과 1사이로 변환된 것을 확인할 수 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6_HNAFat_Pz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CndlWJ2n2ivB",
        "colab_type": "text"
      },
      "source": [
        "> 각 속성별로 최대값과 최소값을 확인해 볼까요? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qURqS862cE2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39d971a4-ad87-4cbc-8268-50e513577e02"
      },
      "source": [
        "np.max(x_data, axis=0)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.       , 1.0000001, 1.       , 1.       ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5-712gS2rJz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0754c0d-df39-4f23-8c61-a6f74fc1efc8"
      },
      "source": [
        "np.min(x_data, axis=0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4yXhhaXRPtX",
        "colab_type": "text"
      },
      "source": [
        "> 입력, 출력 변수의 모양을 확인해 봅니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpOWaWxGtsuC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9914a298-7177-4982-c738-ea33b64b1e0f"
      },
      "source": [
        "x_data.shape, y_data.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((732, 4), (732, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3f8o5LrRZsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBqjRnHxRd_P",
        "colab_type": "text"
      },
      "source": [
        "> 앞서 언급한것 처럼, 이 문제는 **전날의 4가지 입력데이터**에 기반하여 **다음날의 출력데이터(종가)**를 예측하는 것입니다. 이를 위해서 본격적인 모델생성 및 학습 이전에 데이터를 조정할 필요가 있습니다. \n",
        "\n",
        "> 먼저 732일의 개체(일자) 중 첫날과 둘째날의 입력, 출력데이터를 확인해 봅시다.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZwLBB92uPOq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b76ad53c-39e6-4b08-8989-d8115d2b5c9a"
      },
      "source": [
        "x_data[0], y_data[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.97333574, 0.97543156, 1.        , 0.11112306], dtype=float32),\n",
              " array([831.66], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGPq1cIyv7Bb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "76ceb70f-21d2-4dab-cc92-d69d4e48af51"
      },
      "source": [
        "x_data[1], y_data[1]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.95690036, 0.9598812 , 0.98035455, 0.14250247], dtype=float32),\n",
              " array([828.07], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCTyWqep3eft",
        "colab_type": "text"
      },
      "source": [
        "> 사실 우리는 첫째날의 입력데이터(`x_data[0]`)을 기반으로 둘째날의 출력데이터(`y_data[1]`)을 예측하는 것이 목적입니다. \n",
        "> 이렇듯 우리의 자료의 수정이 필요합니다. 이를 위해 입력데이터의 마지막 개체(첫날)와 출력데이터의 첫번째 개체(첫날) 데이터를 삭제합니다.\n",
        "\n",
        ">왜 이런 작업을 했을까요? 우리의 목적을 다시 생각해 봅시다. \n",
        "\n",
        ">우리는 전날의 입력데이터로 다음날의 출력데이터를 예측해야 합니다. \n",
        "\n",
        ">즉, 입력 데이터의 첫번째는 **전날**의 4개 속성(시가, 고가, 저가, 거래량)이 되고, 출력데이터의 첫번째는 **다음날**의 1개 속성(종가)가 되어야 하기 때문입니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj8sOwhquTZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_data = np.delete(x_data, -1, 0)\n",
        "y_data = np.delete(y_data, 0, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0JsL4gYvcBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d6f9147-2991-4b47-8b9d-e56b26ebeb72"
      },
      "source": [
        "x_data.shape, y_data.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((731, 4), (731, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PyTR0tXwj7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaeEmw4DTWHK",
        "colab_type": "text"
      },
      "source": [
        "> 다음은, keras에 내표된 Sequential() 클래스를 사용하여 모델 instance인 model을  만듭니다.\n",
        "\n",
        "> 이어서 1개층, 1개의 unit으로 구성된 신경망을 구성합니다. 한개의 입력 데이터는 4개의 속성을 가지고 있으므로, `input_shape=(4,)`로 정의합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V70FOXmIvrPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=1, input_shape=(4,)))\n",
        "model.compile(optimizer=SGD(lr=0.01), loss='mse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PIBtuXhTwVH",
        "colab_type": "text"
      },
      "source": [
        "> optimizer(gradient descent 알고리즘)와 learning rate, 손실함수를 정의하고 모델을 compile 합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcq_C3PkxNgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTp0q-SKUe0X",
        "colab_type": "text"
      },
      "source": [
        "> 모델을 100번에 걸쳐서 학습합니다. (epochs = 100)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSjOaXNuUd9-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52e79b6c-9e38-4d7e-8bb6-3d8ed9f2a2b8"
      },
      "source": [
        "history = model.fit(x_data, y_data, epochs=100)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "731/731 [==============================] - 0s 242us/step - loss: 221818.5143\n",
            "Epoch 2/100\n",
            "731/731 [==============================] - 0s 30us/step - loss: 46253.6629\n",
            "Epoch 3/100\n",
            "731/731 [==============================] - 0s 31us/step - loss: 11742.1318\n",
            "Epoch 4/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 4675.7927\n",
            "Epoch 5/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 2996.4584\n",
            "Epoch 6/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 2401.1549\n",
            "Epoch 7/100\n",
            "731/731 [==============================] - 0s 25us/step - loss: 2056.5108\n",
            "Epoch 8/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 1793.7932\n",
            "Epoch 9/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 1568.9279\n",
            "Epoch 10/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 1376.3013\n",
            "Epoch 11/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 1209.4356\n",
            "Epoch 12/100\n",
            "731/731 [==============================] - 0s 28us/step - loss: 1063.8114\n",
            "Epoch 13/100\n",
            "731/731 [==============================] - 0s 31us/step - loss: 937.2944\n",
            "Epoch 14/100\n",
            "731/731 [==============================] - 0s 31us/step - loss: 827.8766\n",
            "Epoch 15/100\n",
            "731/731 [==============================] - 0s 33us/step - loss: 732.5927\n",
            "Epoch 16/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 650.2919\n",
            "Epoch 17/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 578.3849\n",
            "Epoch 18/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 516.3807\n",
            "Epoch 19/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 462.2276\n",
            "Epoch 20/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 415.1278\n",
            "Epoch 21/100\n",
            "731/731 [==============================] - 0s 30us/step - loss: 374.2831\n",
            "Epoch 22/100\n",
            "731/731 [==============================] - 0s 32us/step - loss: 338.8327\n",
            "Epoch 23/100\n",
            "731/731 [==============================] - 0s 32us/step - loss: 307.9213\n",
            "Epoch 24/100\n",
            "731/731 [==============================] - 0s 28us/step - loss: 281.0487\n",
            "Epoch 25/100\n",
            "731/731 [==============================] - 0s 28us/step - loss: 257.7362\n",
            "Epoch 26/100\n",
            "731/731 [==============================] - 0s 28us/step - loss: 237.3433\n",
            "Epoch 27/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 219.5960\n",
            "Epoch 28/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 204.1627\n",
            "Epoch 29/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 190.7632\n",
            "Epoch 30/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 179.1888\n",
            "Epoch 31/100\n",
            "731/731 [==============================] - 0s 28us/step - loss: 168.9410\n",
            "Epoch 32/100\n",
            "731/731 [==============================] - 0s 32us/step - loss: 160.0884\n",
            "Epoch 33/100\n",
            "731/731 [==============================] - 0s 30us/step - loss: 152.2185\n",
            "Epoch 34/100\n",
            "731/731 [==============================] - 0s 30us/step - loss: 145.5116\n",
            "Epoch 35/100\n",
            "731/731 [==============================] - 0s 29us/step - loss: 139.4356\n",
            "Epoch 36/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 134.2322\n",
            "Epoch 37/100\n",
            "731/731 [==============================] - 0s 29us/step - loss: 129.6829\n",
            "Epoch 38/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 125.6265\n",
            "Epoch 39/100\n",
            "731/731 [==============================] - 0s 28us/step - loss: 122.1105\n",
            "Epoch 40/100\n",
            "731/731 [==============================] - 0s 28us/step - loss: 118.9539\n",
            "Epoch 41/100\n",
            "731/731 [==============================] - 0s 28us/step - loss: 116.1870\n",
            "Epoch 42/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 113.8171\n",
            "Epoch 43/100\n",
            "731/731 [==============================] - 0s 30us/step - loss: 111.6477\n",
            "Epoch 44/100\n",
            "731/731 [==============================] - 0s 28us/step - loss: 109.6964\n",
            "Epoch 45/100\n",
            "731/731 [==============================] - 0s 28us/step - loss: 108.0176\n",
            "Epoch 46/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 106.4017\n",
            "Epoch 47/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 105.0122\n",
            "Epoch 48/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 103.7439\n",
            "Epoch 49/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 102.6238\n",
            "Epoch 50/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 101.5975\n",
            "Epoch 51/100\n",
            "731/731 [==============================] - 0s 33us/step - loss: 100.6840\n",
            "Epoch 52/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 99.8150\n",
            "Epoch 53/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 99.0119\n",
            "Epoch 54/100\n",
            "731/731 [==============================] - 0s 28us/step - loss: 98.2476\n",
            "Epoch 55/100\n",
            "731/731 [==============================] - 0s 29us/step - loss: 97.5676\n",
            "Epoch 56/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 96.9346\n",
            "Epoch 57/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 96.3135\n",
            "Epoch 58/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 95.8030\n",
            "Epoch 59/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 95.2553\n",
            "Epoch 60/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 94.7912\n",
            "Epoch 61/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 94.2260\n",
            "Epoch 62/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 93.7748\n",
            "Epoch 63/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 93.3885\n",
            "Epoch 64/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 92.9331\n",
            "Epoch 65/100\n",
            "731/731 [==============================] - 0s 28us/step - loss: 92.5052\n",
            "Epoch 66/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 92.1643\n",
            "Epoch 67/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 91.6965\n",
            "Epoch 68/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 91.3607\n",
            "Epoch 69/100\n",
            "731/731 [==============================] - 0s 29us/step - loss: 91.0052\n",
            "Epoch 70/100\n",
            "731/731 [==============================] - 0s 31us/step - loss: 90.6172\n",
            "Epoch 71/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 90.2387\n",
            "Epoch 72/100\n",
            "731/731 [==============================] - 0s 29us/step - loss: 89.9245\n",
            "Epoch 73/100\n",
            "731/731 [==============================] - 0s 28us/step - loss: 89.5676\n",
            "Epoch 74/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 89.2634\n",
            "Epoch 75/100\n",
            "731/731 [==============================] - 0s 28us/step - loss: 88.9007\n",
            "Epoch 76/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 88.5824\n",
            "Epoch 77/100\n",
            "731/731 [==============================] - 0s 31us/step - loss: 88.2867\n",
            "Epoch 78/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 87.9197\n",
            "Epoch 79/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 87.6019\n",
            "Epoch 80/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 87.3286\n",
            "Epoch 81/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 86.9589\n",
            "Epoch 82/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 86.7352\n",
            "Epoch 83/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 86.3903\n",
            "Epoch 84/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 86.1025\n",
            "Epoch 85/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 85.8659\n",
            "Epoch 86/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 85.5835\n",
            "Epoch 87/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 85.2823\n",
            "Epoch 88/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 84.9376\n",
            "Epoch 89/100\n",
            "731/731 [==============================] - 0s 28us/step - loss: 84.6707\n",
            "Epoch 90/100\n",
            "731/731 [==============================] - 0s 29us/step - loss: 84.4398\n",
            "Epoch 91/100\n",
            "731/731 [==============================] - 0s 32us/step - loss: 84.1597\n",
            "Epoch 92/100\n",
            "731/731 [==============================] - 0s 30us/step - loss: 83.8440\n",
            "Epoch 93/100\n",
            "731/731 [==============================] - 0s 29us/step - loss: 83.5981\n",
            "Epoch 94/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 83.2555\n",
            "Epoch 95/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 83.0212\n",
            "Epoch 96/100\n",
            "731/731 [==============================] - 0s 27us/step - loss: 82.7316\n",
            "Epoch 97/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 82.4643\n",
            "Epoch 98/100\n",
            "731/731 [==============================] - 0s 26us/step - loss: 82.2012\n",
            "Epoch 99/100\n",
            "731/731 [==============================] - 0s 31us/step - loss: 81.9081\n",
            "Epoch 100/100\n",
            "731/731 [==============================] - 0s 30us/step - loss: 81.7202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKeshlv1VFL-",
        "colab_type": "text"
      },
      "source": [
        "> 100번의 학습(epoch) 동안 손실함수 값의 변화를 그려보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjhcyk3YUswV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e82b15a2-f818-45dd-ee2a-0b5028416398"
      },
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsQ-0uAXUsdg",
        "colab_type": "text"
      },
      "source": [
        "> 이 모델이 주가 예측을 얼마나 잘 하고 있는지 확인해 볼까요? \n",
        "\n",
        "> 우선, 11번째 입력 데이터를 가지고, 모델의 예측값과, 실제 값을 비교해 보겠습니다. \n",
        "\n",
        "> 우선 11번째 입력데이터를 확인해 보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GafwlJuhViiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = x_data[10].reshape(-1, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8a2AlDeiaM_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a568563-5add-476c-8ee2-20451e6fe1f0"
      },
      "source": [
        "model.predict(test)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[795.3003]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK0HZyahijtr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db1a0add-079a-4ebb-a52f-1c9e068cb329"
      },
      "source": [
        "y_data[10]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([801.49], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdDChRonVrsX",
        "colab_type": "text"
      },
      "source": [
        "> 11일차의 주가 관련 4개의 입력데이터를 확인 할 수 있습니다. \n",
        "그런데, 이 데이터를 모델에 바로 입력할 수 없습니다. \n",
        "그 이유는 여러분이 만든 모델은 rank가 2인 데이터만 입력 받기 때문입니다. 즉, 여러분의 입력데이터(x_data)와 동일한 shape 이어야 합니다(sample 갯수는 제외)\n",
        "따라서 여러분의 데이터를 rank가 2인 데이터로 수정해 줘야 합니다. \n",
        "이때 numpy의 `reshape()` 라는 함수를 사용합니다. \n",
        "`reshape(a,b)`라고 하면, 자료의 shape을 a,b로 변환해줍니다. `reshape(-1,4)`에서 \n",
        "앞의 -1은 알아서 정하라는 의미입니다. 여러분의 데이터는 4개의 요소로 구성되어 있으므로, 4개의 데이터를 감싸는 하나의 축이 더 생성됩니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a9YnA_dzY8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYVG6cNHWiQX",
        "colab_type": "text"
      },
      "source": [
        "> 그럼 이제 test 변수에 저장된 입력 변수를 가지고 모델을 통해서 다음날의 주가 예측을 수행해 볼까요? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i03D9ubgWuIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_si0nz-Wx0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMJBv3OSW1Vd",
        "colab_type": "text"
      },
      "source": [
        "> 실제 다음날의 주가(종가)는 얼마였을까요? 이 값은 출력변수인 y_data에 11번째 개체에 저장되어 있겠죠? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldzHG4YgW7x_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPi6RwdEXIAK",
        "colab_type": "text"
      },
      "source": [
        "이 두 값을 한번에 표현해 보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLj7uLofzoIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uU0mn4bXWOY",
        "colab_type": "text"
      },
      "source": [
        "> 같은 작업을 31번째 데이터(31일차)에 대해서도 해볼까요? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeWBD0Hdzy6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snalxDXazzCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3drorh67Xfo2",
        "colab_type": "text"
      },
      "source": [
        "> 얼추 비슷하게 맞는것 같습니까? \n",
        "\n",
        "> 축하합니다. 여러분은 단순한 신경망을 구성하여 주가를 예측하는 프로그램을 만드셨습니다. "
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of sung_lec02_multilinear_regression(1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sturu1/git-first/blob/master/Copy_of_sung_lec02_multilinear_regression(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nltjgGJEpvbe",
        "colab_type": "text"
      },
      "source": [
        "# Mutiple Regression 실습(1)\n",
        "\n",
        "> multiple regression(다중회귀분석)이란것은 앞에서 배운 단순(simple) 회귀분석을 **입력변수가 여러개**일때로 확장한 개념입니다. \n",
        "예를 들면 입력변수가 3개일때는 수학적으로 다음과 같은 표현이 되겠죠. \n",
        "`\n",
        "y=w1*x1 + w2*x2 + w3*x3 +b\n",
        "`\n",
        "\n",
        "> 이번 실습에서는 출석, 중간, 기말성적 이라는 3가지 속성(입력변수 3개)을 이용하여 최종 성적(출력변수 1개)을 예측하는 모델을 구축해 보도록 하겠습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGMG9oqxEZYb",
        "colab_type": "text"
      },
      "source": [
        "> 먼저 deep learning 모듈인 keras와 데이터 조작을 위한 모듈인 numpy를 불러옵니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGCvbdd_gH9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H62qe0z2_ZZ4",
        "colab_type": "text"
      },
      "source": [
        "> 다음으로 학습을 위한 데이터를 변수에 저장합니다. \n",
        "아래서 보는바와 같이 입력데이터는 5개의 개체(sample)가 있으며, 각 개체별로 3개의 변수(속성)를 갖고 있습니다. 즉, 5명의 학생이 있고, 3개의 속성(출석점수, 중간성적, 기말성적)으로 입력데이터가 구성되어 있습니다. \n",
        "또한 출력데이터는 5개의 개체와 각 개체별 1개의 속성으로 구성되어 있습니다. 즉, 각 학생별 최종성적입니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZzT3mmsggk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_data = np.array([[73., 80., 75.],\n",
        "                   [93., 88., 93.],\n",
        "                   [89., 91., 90.],\n",
        "                   [96., 98., 100.],\n",
        "                   [73., 66., 70.]])\n",
        "y_data = np.array([[152.],\n",
        "                   [185.],\n",
        "                   [180.],\n",
        "                   [196.],\n",
        "                   [142.]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER3E69uLFMR3",
        "colab_type": "text"
      },
      "source": [
        "> 입출력 데이터의 확인을 위해, 각 입출력 변수의 자료 모양을 확인해 봅니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wELMyPngjlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f904f27-1025-45da-bcc7-825868e38a7d"
      },
      "source": [
        "x_data.shape, y_data.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5, 3), (5, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-jOoqpDFgIF",
        "colab_type": "text"
      },
      "source": [
        "> 다음은, keras에 내표된 Sequential() 클래스를 사용하여 모델 instance를  만듭니다. Sequential()은 신경망을 순차적으로 (layer by layer) 구성하기 위하여 사용하는 함수(클래스)로 우리 강의의 대부분의 예제에서 활용합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqQlJrENglaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7Q__x41GUWe",
        "colab_type": "text"
      },
      "source": [
        "> 생성된 model instance는 현재 비어 있습니다. 여기에 신경망의 층(layers)과 셀(unit)을 추가할 수 있습니다. \n",
        "\n",
        "> 우리는 단순히 **한개의 layer**와 **한개의 unit**으로 구성된 아주 단순한 신경망을 구성하겠습니다. 마치 하나의 세포(뉴런)으로만 구성된 뇌와 같습니다. \n",
        "\n",
        "> 이때, 입력데이터의 각 개체의 모양을 input_shape로 정의하는 것이 필요합니다. input 데이터는 5개의 개체(5명의 학생)로 이루어져 있지만, 한 개체는 3개의 속성을 가지고 있으므로 **inpu_shape는 1D 벡터인 (3,)**로 지정합니다. 또는 input_dim=3 으로 표현하기도 합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2Y-46nXGScA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(units=1, input_shape=(3, )))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMg_9DQRh1zX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "> 참고로 윗 코드는 다음과 같이 표현 가능\n",
        "```\n",
        "model=Sequential()\n",
        "model.add(Dense(units=1,input_dim=3))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqBOsQuXIsp-",
        "colab_type": "text"
      },
      "source": [
        "> **모델을 생성**하고, **네트워크의구조를 정의**했으면 다음으로 **모델을 compile** 해야 합니다. 이때 **손실함수와 optimizer를 정의**해야 합니다. \n",
        "\n",
        "> 이 예제에서는 optimizer로 rmsprop 알고리즘을 사용했습니다. 또한 이 예제가 숫자를 예측하는 회귀분석 이므로 손실함수로 mse(평균제곱오차, Mean Squared Error)를 사용했군요. 참고로, optimizer로 사용할수 있는 알고리즘은 여러가지가 있는데 가장 대표적으로 RMSprop나 SGM, Adam 등이 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYKtIStjgpSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=RMSprop(lr=0.1), loss='mse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMYNueGmxR-8",
        "colab_type": "text"
      },
      "source": [
        "> 이제 모델의 구축은 끝났습니다. 지금까지 구축한 모델의 요약정보를 확인해 봅니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4fnRu9UxjA7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "bcb3b0f6-fdd6-4c50-c7dd-eb8a71400510"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5S-rp3NxmRj",
        "colab_type": "text"
      },
      "source": [
        "> 우리가 구성한 모델은 1개의 층으로 이루어져 있으며 (layer에 dense_1 하나만 존재), 출력 데이터의 형태는 1개의 속성으로 구성됩니다. 또한 총 4개의 파라미터가 있는데 아래 식의 w1, w2, w3와 b가 되겠죠. `y= w1*x1 + w2*x2 + w3*x3 + b`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UPISRdOJBmO",
        "colab_type": "text"
      },
      "source": [
        "> 이제 모델을 100회에 걸쳐서 학습시킵니다(epochs = 100). 참고로 주어진 입력데이터를 모두 사용하여 한번 학습시킬때 epochs=1이 됩니다. \n",
        "\n",
        "\n",
        "> 학습 과정에서 mse인 손실 함수의 값이 점차 감소하는 것을 알 수 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELb2wcxOIq3O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8cf0da64-028c-4a60-b483-f956b0009349"
      },
      "source": [
        "history = model.fit(x_data, y_data, epochs=100)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 9864.5879\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 313us/step - loss: 319.1887\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 301us/step - loss: 11.7118\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 299us/step - loss: 4.7910\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 318us/step - loss: 4.7112\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 330us/step - loss: 4.7056\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 563us/step - loss: 4.6998\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 573us/step - loss: 4.6938\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 364us/step - loss: 4.6874\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 335us/step - loss: 4.6807\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 275us/step - loss: 4.6737\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 255us/step - loss: 4.6663\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 273us/step - loss: 4.6585\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 303us/step - loss: 4.6503\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 253us/step - loss: 4.6416\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 250us/step - loss: 4.6325\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 260us/step - loss: 4.6230\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 256us/step - loss: 4.6130\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 288us/step - loss: 4.6024\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 257us/step - loss: 4.5913\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 285us/step - loss: 4.5796\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 378us/step - loss: 4.5673\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 277us/step - loss: 4.5544\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 313us/step - loss: 4.5409\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 306us/step - loss: 4.5266\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 298us/step - loss: 4.5116\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 294us/step - loss: 4.4959\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 273us/step - loss: 4.4794\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 249us/step - loss: 4.4621\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 222us/step - loss: 4.4440\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 226us/step - loss: 4.4257\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 293us/step - loss: 4.4130\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 254us/step - loss: 4.4641\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 248us/step - loss: 5.2654\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 397us/step - loss: 15.9387\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 264us/step - loss: 166.1525\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 238us/step - loss: 1401.7379\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 244us/step - loss: 1216.5541\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 250us/step - loss: 353.4232\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 223us/step - loss: 98.1815\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 257us/step - loss: 35.0578\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 251us/step - loss: 17.1608\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 279us/step - loss: 11.1532\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 336us/step - loss: 8.9055\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 265us/step - loss: 8.1623\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 254us/step - loss: 8.3038\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 254us/step - loss: 9.3788\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 253us/step - loss: 12.0897\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 262us/step - loss: 18.5432\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 276us/step - loss: 34.7679\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 320us/step - loss: 78.0253\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 265us/step - loss: 190.8579\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 249us/step - loss: 414.6027\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 273us/step - loss: 589.4831\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 269us/step - loss: 485.8694\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 259us/step - loss: 288.4139\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 237us/step - loss: 159.4657\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 243us/step - loss: 95.1025\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 241us/step - loss: 65.0267\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 245us/step - loss: 51.8298\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 240us/step - loss: 48.0395\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 265us/step - loss: 51.3482\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 274us/step - loss: 62.6161\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 267us/step - loss: 85.5980\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 270us/step - loss: 126.8299\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 225us/step - loss: 191.7878\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 227us/step - loss: 270.7541\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 288us/step - loss: 324.9648\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 251us/step - loss: 317.5640\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 266us/step - loss: 262.3749\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 273us/step - loss: 199.3276\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 257us/step - loss: 150.8315\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 251us/step - loss: 120.0190\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 264us/step - loss: 103.3973\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 236us/step - loss: 97.5252\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 264us/step - loss: 100.6076\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 251us/step - loss: 112.3316\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 255us/step - loss: 133.0780\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 368us/step - loss: 162.3283\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 312us/step - loss: 196.0937\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 369us/step - loss: 225.1984\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 245us/step - loss: 238.6375\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 249us/step - loss: 231.8111\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 288us/step - loss: 210.2181\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 287us/step - loss: 183.8841\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 250us/step - loss: 160.5153\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 257us/step - loss: 143.6284\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 228us/step - loss: 133.9763\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 246us/step - loss: 131.2207\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 241us/step - loss: 134.7854\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 218us/step - loss: 143.9798\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 246us/step - loss: 157.6554\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 359us/step - loss: 173.6731\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 251us/step - loss: 188.6796\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 249us/step - loss: 198.8218\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 269us/step - loss: 201.4188\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 289us/step - loss: 196.4031\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 266us/step - loss: 186.1870\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 225us/step - loss: 174.1652\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 255us/step - loss: 163.2400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__5u1pshJrwt",
        "colab_type": "text"
      },
      "source": [
        "> model의 weight 값을 아래와 같이 확인할 수 있습니다. > 즉, `w1`, `w2`, `w3` 값과, `b` 값에 해당합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k9GZhjtJn-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6fb57bb2-b425-4eec-e291-54d01ca48ff7"
      },
      "source": [
        "model.weights"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_2/kernel:0' shape=(3, 1) dtype=float32, numpy=\n",
              " array([[1.4842305 ],\n",
              "        [0.17180961],\n",
              "        [0.21208096]], dtype=float32)>,\n",
              " <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.28987008], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDZdzZOXvDaz",
        "colab_type": "text"
      },
      "source": [
        "> 학습이 진행되는 동안 손실값은 history.history라는 변수에 dictionary 형태로 저장되어 있습니다. 따라서 여러분은 다음과 같이 100번의 반복동안 손실함수의 값(mse)을 확인할 수 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th3v7_BCKdqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3AfWea2J6D2",
        "colab_type": "text"
      },
      "source": [
        "> 다음으로 학습이 진행되면서 (epochs이 진행되면서) 손실값의 변화를 그래프로 그려보겠습니다. \n",
        "\n",
        "> 그래프를 그리는 도구인 matplotlib 모듈을 사용하겠습니다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsnQLVcmKEFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "71838185-ccf5-4052-cac2-630107cb88f0"
      },
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.title(\"Model loss\")\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc64M8zTJDM-",
        "colab_type": "text"
      },
      "source": [
        "> 모델의 학습이 끝났으니, 새로운 데이터에 대한 예측을 수행해 볼까요? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sP9hnwkgr47",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fc53e98d-e277-45b1-c51c-8a3bf38d5076"
      },
      "source": [
        "model.predict(np.array([[95,88,60],[67,99,70]]))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[169.13586],\n",
              "       [131.58813]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y0lJTRyI8T3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}